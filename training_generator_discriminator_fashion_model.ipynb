{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gan para generar prendas de ropa y accesorios\n",
    "\n",
    "Para este proyecto usaremos el dataset que tiene por defecto *keras* el cual es `fasion_mnist`.\n",
    "\n",
    "El objetivo será crear un generador de imágenes de prendas de ropas y accesorios, para ello entrenaremos una *red generativa adversaria*, donde un generador y un discriminador se entrenarán mutuamente para afinar el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y muestra de las imágenes del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear constantes del dataset y modelo\n",
    "\n",
    "Declarando las siguientes constantes conseguiremos que para aumentar el rendimiento del modelo sea mucho más sencillo, solo tendremos que modificar estos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (28, 28)\n",
    "BATCH_SIZE = 32\n",
    "NUMBER_OF_FILES = 70000\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 100 # Semilla del generador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaremos a continuación el dataset y normalizaremos los datos preparandolo para nuestro posterior entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el dataset\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Concatenamos los datos de entrenamiento y test en un solo array. \n",
    "# Los valores de y no nos interesan, por lo que no los concatenamos ni haremos nada con ellos\n",
    "images = np.concatenate((X_train, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tendremos 70000 imagenes\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos mostrar algunas imagenes\n",
    "sample_images = random.sample(list(images), 5)\n",
    "count = 1\n",
    "for image in sample_images:\n",
    "    plt.figure(dpi=50)\n",
    "    plt.title(f\"Image {count}\")\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    count+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que haremos es capar el número de imágenes que usaremos para el modelo, posteriormente cambiando las constantes de arriba podremos probar con un lote mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[:NUMBER_OF_FILES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora un paso importante que debemos de hacer es normalizar entre $-1$ y $1$, que es lo ideal para nuestro modelo de generación e inicializar el dataset de tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_images = images / 127.5 - 1.0\n",
    "dataset_images = tf.expand_dims(dataset_images, -1) # Añadimos una dimensión para el canal de color\n",
    "dataset_images = tf.data.Dataset.from_tensor_slices(dataset_images).shuffle(NUMBER_OF_FILES).batch(BATCH_SIZE)\n",
    "print(f\"Dataset procesado: {NUMBER_OF_FILES} imágenes cargadas y preparadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a verificar las dimensiones del lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataset_images.take(1):\n",
    "    print(\"Dimensiones del lote:\", batch.shape)\n",
    "    print(f\"Rango: ({batch.numpy().min()} a {batch.numpy().max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de la **GAN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.Sequential([\n",
    "    layers.Input(shape=(LATENT_DIM,), name=\"gen_input_layer\"),\n",
    "\n",
    "    layers.Dense(7*7*128, name=\"gen_first_dense_layer\"),\n",
    "    layers.BatchNormalization(name=\"gen_first_bn_layer\"),\n",
    "    layers.LeakyReLU(name=\"gen_first_leakyrelu_layer\"),\n",
    "\n",
    "    layers.Reshape((7, 7, 128), name=\"gen_reshape_layer\"),\n",
    "\n",
    "    # Primera capa convolucional transpuesta: de 7x7 a 14x14\n",
    "    layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding=\"same\", activation=\"selu\", name=\"gen_first_conv2d_layer\"),\n",
    "    layers.BatchNormalization(name=\"gen_second_bn_layer\"),\n",
    "    layers.LeakyReLU(name=\"gen_second_leakyrelu_layer\"),\n",
    "\n",
    "    # Segunda capa convolucional transpuesta, OUTPUT: de 14x14 a 28x28\n",
    "    layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding=\"same\", activation=\"tanh\", name=\"gen_second_conv2d_layer\"),\n",
    "])\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probaremos el generador antes del entrenamiento\n",
    "\n",
    "Primero de todos deberemos de crear ruido, que será lo que introduzcamos como entrada para generar las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, LATENT_DIM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = generator(noise, training=False)\n",
    "print(\"Dimensiones de la imagen generada:\", generated_image.shape)\n",
    "print(\"Rango de valores de la imagen generada:\", generated_image.numpy().min(), \"-\", generated_image.numpy().max())\n",
    "plt.figure(dpi=40)\n",
    "plt.imshow((generated_image[0] + 1) / 2, cmap=\"grey\") # Reescala la imagen al rango [0, 1] para visualizarla \n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del Descriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = keras.Sequential([\n",
    "    layers.Input(shape=(28, 28, 1), name=\"dis_input_layer\"),\n",
    "\n",
    "    # Primera capa convolucional\n",
    "    layers.Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\", name=\"dis_first_conv2d_layer\"),\n",
    "    layers.LeakyReLU(name=\"dis_first_leakyrelu_layer\"),\n",
    "    layers.Dropout(0.3, name=\"dis_first_dropout_layer\"),\n",
    "\n",
    "    # Segunda capa convolucional\n",
    "    layers.Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\", name=\"dis_second_conv2d_layer\"),\n",
    "    layers.LeakyReLU(name=\"dis_second_leakyrelu_layer\"),\n",
    "    layers.Dropout(0.3, name=\"dis_second_dropout_layer\"),\n",
    "\n",
    "    layers.Flatten(name=\"dis_flatten_layer\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"dis_output_layer\"),\n",
    "])\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comprobación del discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = discriminator(generated_image)\n",
    "print(\"Decision:\", decision.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializar optimizadores y función de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "generator_optimizer = Adam(1e-4)\n",
    "discriminator_optimizer = Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de la GAN y carga de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo desde local si existe, con la mayor epoca:\n",
    "\n",
    "def load_latest_models(model_dir=\"models\"):\n",
    "    \"\"\"Carga el ultimo modelo guardado si existe\"\"\"\n",
    "    try:\n",
    "        generator_files = [f for f in os.listdir(model_dir) if f.startswith(\"generador_caras_\")]\n",
    "        if not generator_files:\n",
    "            return None, None, 0\n",
    "        \n",
    "        # Parsear y extraer (época, imágenes) de los nombres\n",
    "        file_info = []\n",
    "        for file in generator_files:\n",
    "            # Formato: generador_fashion_{epoch}ep_{imgCount}img.keras\n",
    "            parts = file.split(\"_\")  \n",
    "            epoch_str = parts[2].replace(\"ep\", \"\")\n",
    "            img_str = parts[3].replace(\"img.keras\", \"\")\n",
    "            epoch = int(epoch_str)\n",
    "            img_count = int(img_str)\n",
    "            file_info.append((epoch, img_count, file))\n",
    "\n",
    "        # Ordenar: primero por número de imágenes, luego por época, ambos descendentes\n",
    "        file_info.sort(key=lambda x: (x[1], x[0]), reverse=True)\n",
    "        best_epoch, highest_img_count, _ = file_info[0]\n",
    "\n",
    "        # Cargar modelo\n",
    "        generator = tf.keras.models.load_model(\n",
    "            f\"models/generador_fashion_{best_epoch}ep_{highest_img_count}img.keras\"\n",
    "        )\n",
    "        discriminator = tf.keras.models.load_model(\n",
    "            f\"models/discriminador_fashion_{best_epoch}ep_{highest_img_count}img.keras\"\n",
    "        )\n",
    "\n",
    "        return generator, discriminator, best_epoch\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading models: {str(e)}\")\n",
    "        return None, None, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(resume_epoch=0, epochs=EPOCHS):\n",
    "    for epoch in tqdm(range(resume_epoch, epochs)):\n",
    "        print(f\"Época {epoch + 1}/{EPOCHS}...\") \n",
    "\n",
    "        for real_images in dataset_images: \n",
    "            current_batch_size = real_images.shape[0]\n",
    "\n",
    "            noise = tf.random.normal([current_batch_size, LATENT_DIM])\n",
    "\n",
    "            generated_images = generator(noise, training=True)\n",
    "\n",
    "            real_labels = tf.ones((current_batch_size, 1)) \n",
    "            false_labels = tf.zeros((current_batch_size, 1)) \n",
    "\n",
    "            with tf.GradientTape() as disc_tape: \n",
    "                real_output = discriminator(real_images, training=True)\n",
    "                fake_output = discriminator(generated_images, training=True)\n",
    "                disc_loss_real = cross_entropy(real_labels, real_output)\n",
    "                disc_loss_fake = cross_entropy(false_labels, fake_output)\n",
    "                disc_loss = disc_loss_real + disc_loss_fake\n",
    "\n",
    "            gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "            discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "            noise = tf.random.normal([current_batch_size, LATENT_DIM])\n",
    "\n",
    "            with tf.GradientTape() as gen_tape: \n",
    "                generated_images = generator(noise, training=True)\n",
    "                fake_output = discriminator(generated_images, training=False)\n",
    "                gen_loss = cross_entropy(real_labels, fake_output)\n",
    "\n",
    "            gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "            generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "\n",
    "        print(f\"Pérdida del discriminador: {disc_loss.numpy()}, Pérdida del generador: {gen_loss.numpy()}\")\n",
    "\n",
    "        if (epoch + 1) % 10 == 0 or epoch == EPOCHS - 1:\n",
    "            noise = tf.random.normal([16, LATENT_DIM])\n",
    "            generated_images = generator(noise, training=False)\n",
    "            generated_images = (generated_images + 1) / 2 \n",
    "\n",
    "\n",
    "            fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "            for img, ax in zip(generated_images, axes.flatten()):\n",
    "                ax.imshow(img, cmap=\"gray\")\n",
    "                ax.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "            generator.save(f\"models/generador_fashion_{epoch+1}ep_{NUMBER_OF_FILES}img.keras\")\n",
    "            discriminator.save(f\"models/discriminador_fashion_{epoch+1}ep_{NUMBER_OF_FILES}img.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de la GAN\n",
    "generator_loaded, discriminator_loaded, highest_epoch = load_latest_models(\"models\")\n",
    "\n",
    "if generator_loaded is not None and discriminator_loaded is not None and highest_epoch >= EPOCHS:\n",
    "    print(f\"Modelos cargados de la época {highest_epoch}. Tareas completas.\")\n",
    "elif generator_loaded is not None and discriminator_loaded is not None:\n",
    "    print(f\"Modelos cargados de la época {highest_epoch}. Continuando con el entrenamiento...\")\n",
    "    # Hacer un entrenamiento desde la epoca que estuviera hasta la epoca deseada\n",
    "    generator = generator_loaded\n",
    "    discriminator = discriminator_loaded\n",
    "    train_gan(resume_epoch=highest_epoch, epochs=EPOCHS)\n",
    "else:\n",
    "    print(f\"No se han encontrado modelos de forma local, continuaremos con un modelo desde cero...\")\n",
    "    # Hacer el entrenamiento desde cero\n",
    "    train_gan(resume_epoch=0, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probar el generador cargado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, LATENT_DIM])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "print(\"Dimensiones de la imagen generada:\", generated_image.shape)\n",
    "print(\"Rango de valores de la imagen generada:\", generated_image.numpy().min(), \"-\", generated_image.numpy().max())\n",
    "\n",
    "plt.figure(dpi=40)\n",
    "plt.imshow((generated_image[0] + 1) / 2, cmap=\"gray\") \n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, generaremos 100 imágenes de muestra para tener una aproximación de qué tan optimizado es nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_sample_images = 100\n",
    "\n",
    "for i in range(number_of_sample_images):\n",
    "    generated_image = generator(noise, training=False)\n",
    "    generated_image = (generated_image + 1) / 2\n",
    "    plt.figure(dpi=50)\n",
    "    plt.imsave(fname=f\"samples_generated/image_{i}.png\", arr=generated_image[0], cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
